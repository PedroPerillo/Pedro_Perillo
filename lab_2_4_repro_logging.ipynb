{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc7363d-f2bc-439d-9b7c-84f99c3ce001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "log_filename = f\"logs/run_{datetime.now().strftime('%Y%m%d_%H%M')}.log\"\n",
    "log_format = \"%(asctime)s | %(levelname)s | %(message)s\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=log_format,\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(log_filename)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41439ba8-8f79-4b53-a12e-e1377dd29eb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Log the start of the run\n",
    "logging.info(\"Run started.\")\n",
    "\n",
    "# Log cluster/runtime info\n",
    "cluster_id = os.environ.get(\"DATABRICKS_CLUSTER_ID\", \"unknown\")\n",
    "runtime_version = os.environ.get(\"DATABRICKS_RUNTIME_VERSION\", \"unknown\")\n",
    "logging.info(f\"Cluster ID: {cluster_id}\")\n",
    "logging.info(f\"Databricks Runtime Version: {runtime_version}\")\n",
    "\n",
    "# Log configuration values\n",
    "config_values = {\n",
    "    \"log_filename\": log_filename,\n",
    "    \"log_format\": log_format,\n",
    "    \"log_level\": logging.getLevelName(logging.getLogger().level)\n",
    "}\n",
    "logging.info(f\"Configuration values: {config_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1dcac1c-4ba3-44e9-b82e-165ff18a06da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, random, numpy as np\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5efbe7c-a46f-4394-b1bf-210b516d57c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aac61d1-9219-4a52-b4b4-9f4f3f2a7991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import glob\n",
    "\n",
    "input_csv_files = glob.glob(\"data/*.csv\")\n",
    "data_hashes = {}\n",
    "\n",
    "for csv_file in input_csv_files:\n",
    "    with open(csv_file, \"rb\") as f:\n",
    "        file_bytes = f.read()\n",
    "        sha256_hash = hashlib.sha256(file_bytes).hexdigest()\n",
    "        data_hashes[csv_file] = sha256_hash\n",
    "        logging.info(f\"SHA-256 for {csv_file}: {sha256_hash}\")\n",
    "\n",
    "with open(\"data_hashes.json\", \"w\") as json_file:\n",
    "    json.dump(data_hashes, json_file, indent=2)\n",
    "logging.info(\"Saved SHA-256 hashes to data_hashes.json.\")\n",
    "\n",
    "logging.info(f\"Loaded dataframes: {list(dfs.keys())}\")\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0909387-3c3d-447e-9d3e-367f62bd4d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_files = glob.glob(\"data/*.csv\")\n",
    "dfs = {os.path.basename(f): pd.read_csv(f) for f in csv_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99864cb9-dcc3-42f2-b2ad-e70ae0f205a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    # Convert date columns\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    # Trim text columns\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "    # Correct numeric columns\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "        except Exception:\n",
    "            pass\n",
    "    dfs[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9f5602-cf31-428f-987c-2b2a054c7301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "menu_df = dfs[\"menu_items.csv\"]\n",
    "orders_df = dfs[\"order_details.csv\"]\n",
    "\n",
    "joined_df = orders_df.merge(\n",
    "    menu_df,\n",
    "    left_on=\"item_id\",\n",
    "    right_on=\"menu_item_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "logging.info(f\"Joined DataFrame shape: {joined_df.shape}\")\n",
    "joined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f271ea5-927d-4120-a9d6-a305ae10b6d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine date + time into single timestamp\n",
    "joined_df[\"order_datetime\"] = pd.to_datetime(\n",
    "    joined_df[\"order_date\"].astype(str) + \" \" + joined_df[\"order_time\"].astype(str),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Assume quantity = 1 (since dataset lacks it)\n",
    "joined_df[\"quantity\"] = 1\n",
    "\n",
    "# Select tidy columns\n",
    "tidy_df = joined_df[[\n",
    "    \"order_id\",\n",
    "    \"order_datetime\",\n",
    "    \"item_name\",\n",
    "    \"category\",\n",
    "    \"price\",\n",
    "    \"quantity\"\n",
    "]].copy()\n",
    "\n",
    "# Compute revenue\n",
    "tidy_df[\"revenue\"] = tidy_df[\"price\"] * tidy_df[\"quantity\"]\n",
    "\n",
    "logging.info(f\"Tidy DataFrame shape: {tidy_df.shape}\")\n",
    "tidy_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da942892-686d-4f14-abf7-837d3cf8c11e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logging.info(\"Computing metrics\")\n",
    "\n",
    "# 1. Top 5 items by quantity\n",
    "top_items = (\n",
    "    tidy_df.groupby(\"item_name\")[\"quantity\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"quantity\": \"total_quantity\"})\n",
    ")\n",
    "\n",
    "# 2. Revenue by category\n",
    "revenue_by_cat = (\n",
    "    tidy_df.groupby(\"category\")[\"revenue\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Busiest hour of the day\n",
    "tidy_df[\"hour\"] = tidy_df[\"order_datetime\"].dt.hour\n",
    "busiest_hour = (\n",
    "    tidy_df.groupby(\"hour\")[\"order_id\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"order_id\": \"order_count\"})\n",
    "    .sort_values(\"order_count\", ascending=False)\n",
    ")\n",
    "\n",
    "logging.info(\"Metrics computed\")\n",
    "top_items, revenue_by_cat, busiest_hour.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7852678b-49ae-4121-b805-3ec9d809823c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print(\"üìà Top 5 Items by Quantity\")\n",
    "display(top_items)\n",
    "\n",
    "print(\"\\nüí∞ Revenue by Category\")\n",
    "display(revenue_by_cat)\n",
    "\n",
    "print(\"\\n‚è∞ Busiest Hour of Day\")\n",
    "display(busiest_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b09dc47-4a97-4b5f-82b5-2f1c5e540984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Add metric labels\n",
    "top_items_labeled = top_items.copy()\n",
    "top_items_labeled[\"metric\"] = \"top_items_by_quantity\"\n",
    "\n",
    "revenue_by_cat_labeled = revenue_by_cat.copy()\n",
    "revenue_by_cat_labeled[\"metric\"] = \"revenue_by_category\"\n",
    "\n",
    "busiest_hour_labeled = busiest_hour.copy()\n",
    "busiest_hour_labeled[\"metric\"] = \"busiest_hour_of_day\"\n",
    "\n",
    "# Combine all metrics\n",
    "metrics_df = pd.concat(\n",
    "    [top_items_labeled, revenue_by_cat_labeled, busiest_hour_labeled],\n",
    "    ignore_index=True,\n",
    "    sort=False\n",
    ")\n",
    "\n",
    "logging.info(f\"Combined metrics DataFrame shape: {metrics_df.shape}\")\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# --- Always save to repo for versioning ---\n",
    "repo_output_dir = \"etl_output\"\n",
    "os.makedirs(repo_output_dir, exist_ok=True)\n",
    "repo_output_path = f\"{repo_output_dir}/metrics_{ts}.csv\"\n",
    "metrics_df.to_csv(repo_output_path, index=False)\n",
    "logging.info(f\"Saved metrics to repo path: {repo_output_path}\")\n",
    "\n",
    "metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670edc60-5255-4718-93ae-b9f41b222954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logging.info(\"Running assert tests\")\n",
    "\n",
    "# 1. Tidy DataFrame should not be empty\n",
    "assert not tidy_df.empty, \"Tidy DataFrame is empty!\"\n",
    "\n",
    "# 2. Tidy DataFrame columns check\n",
    "expected_cols = {\n",
    "    \"order_id\",\n",
    "    \"order_datetime\",\n",
    "    \"item_name\",\n",
    "    \"category\",\n",
    "    \"price\",\n",
    "    \"quantity\",\n",
    "    \"revenue\",\n",
    "}\n",
    "missing_cols = expected_cols - set(tidy_df.columns)\n",
    "assert not missing_cols, f\"Missing expected columns in tidy_df: {missing_cols}\"\n",
    "\n",
    "# 3. Metrics DataFrame should not be empty\n",
    "assert not metrics_df.empty, \"Metrics DataFrame is empty!\"\n",
    "\n",
    "# 4. Metrics completeness\n",
    "expected_metrics = {\n",
    "    \"top_items_by_quantity\",\n",
    "    \"revenue_by_category\",\n",
    "    \"busiest_hour_of_day\",\n",
    "}\n",
    "present_metrics = set(metrics_df[\"metric\"].unique())\n",
    "missing_metrics = expected_metrics - present_metrics\n",
    "assert not missing_metrics, f\"Missing metrics in metrics_df: {missing_metrics}\"\n",
    "\n",
    "logging.info(\"All assert tests passed ‚úîÔ∏è\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lab_2_4_repro_logging",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
