{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f16c4c5d-a5a1-42a9-b022-cf4af0754911",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries and Load Your Feature Pipeline"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "pipeline = joblib.load(\n",
    "   \"/Workspace/Users/pedrofp@ensign.edu/stedi_curated_pipeline/stedi_feature_pipeline.pkl\"\n",
    ")\n",
    "X_train_transformed = joblib.load(\n",
    "   \"/Workspace/Users/pedrofp@ensign.edu/stedi_curated_pipeline/X_train_transformed.pkl\"\n",
    ")\n",
    "X_test_transformed = joblib.load(\n",
    "   \"/Workspace/Users/pedrofp@ensign.edu/stedi_curated_pipeline/X_test_transformed.pkl\"\n",
    ")\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "   \"\"\"\n",
    "   Ensures that input arrays (possibly object-dtype, sparse, or 0-d) are converted to a 2-D float matrix.\n",
    "   This is necessary because saved feature arrays may have inconsistent shapes or types after transformation,\n",
    "   and ML models require numeric 2-D arrays for training and prediction.\n",
    "   \"\"\"\n",
    "   if arr.ndim == 0:\n",
    "       # Handle 0-d array directly\n",
    "       arr = arr.item()\n",
    "       if issparse(arr):\n",
    "           arr = arr.toarray()\n",
    "       arr = np.array(arr, dtype=float)\n",
    "   elif arr.dtype == object:\n",
    "       arr = np.array([\n",
    "           x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "           for x in arr\n",
    "       ])\n",
    "       arr = np.vstack(arr)\n",
    "   elif issparse(arr):\n",
    "       arr = arr.toarray()\n",
    "   else:\n",
    "       arr = np.array(arr, dtype=float)\n",
    "   return arr\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "y_train = joblib.load(\n",
    "   \"/Workspace/Users/pedrofp@ensign.edu/stedi_curated_pipeline/y_train.pkl\"\n",
    ")\n",
    "y_test = joblib.load(\n",
    "   \"/Workspace/Users/pedrofp@ensign.edu/stedi_curated_pipeline/y_test.pkl\"\n",
    ")\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1bac92d-3487-40ae-b14d-b49ac952130c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train Logistic Regression"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f553bb61-0817-4110-a329-bc0380ac6af0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train Random Forest"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d6efde-fb2f-4e6e-9d4b-22c5231a8e1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Compare Baseline Models"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "498765a9-7446-406d-b595-2fd4bcbe6f06",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Model Comparison Discussion"
    }
   },
   "source": [
    "## Model Comparison Discussion\n",
    "* Which baseline model performed better?\n",
    "    - Logistic Regression\n",
    "* Which model seems more stable for noisy sensor data?\n",
    "    - Random Forest, because it averages many trees and handles noise better.\n",
    "* What questions do you have about why the numbers differ?\n",
    "    - Are features, preprocessing, and data balance the same for both models?\n",
    "* Why is it important to test your model before using it in real life?\n",
    "    - To ensure it works on new data and avoids harmful mistakes.\n",
    "* If a model is wrong, who could be affected?\n",
    "    - Anyone relying on its predictions: users, customers, organizations.\n",
    "* Why does fairness matter in both data science and discipleship?\n",
    "    - It prevents harm, builds trust, and reflects respect, we do pur best to pick the best option and that is always better for everyone\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acd4ce66-bf72-44ba-a4ac-ef9735542beb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Training Summary\n",
    "\n",
    "* I trained two machine-learning algorithms: Logistic Regression and Random Forest.\n",
    "* I tuned the max_iter hyperparameter for Logistic Regression and used default settings for Random Forest.\n",
    "* Random Forest performed best, achieving higher accuracy on the test set.\n",
    "* I selected Random Forest because it is more robust to noisy sensor data and generalizes better for step detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "480156ee-fe71-4596-ac17-b5c9dc152111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "# Create a unique folder name (prevents overwriting files)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_dir = f\"/Workspace/Users/pedrofp@ensign.edu/stedi_models/{run_id}\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "# Save trained models\n",
    "joblib.dump(log_reg, f\"{base_dir}/log_reg.joblib\")\n",
    "joblib.dump(rf, f\"{base_dir}/random_forest.joblib\")\n",
    "# Save accuracy information (metadata)\n",
    "metadata = {\n",
    "\"run_id\": run_id,\n",
    "\"logistic_regression_accuracy\": float(log_reg_score),\n",
    "\"random_forest_accuracy\": float(rf_score),\n",
    "}\n",
    "joblib.dump(metadata, f\"{base_dir}/metadata.joblib\")\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a062ae4-0be9-4b08-9594-f07793f0a5a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "zip_path = f\"/Workspace/Users/pedrofp@ensign.edu/stedi_models/{run_id}.zip\"\n",
    "shutil.make_archive(zip_path.replace(\".zip\", \"\"), \"zip\", base_dir)\n",
    "zip_path"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.4 Trained ML Models: Compare Models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
